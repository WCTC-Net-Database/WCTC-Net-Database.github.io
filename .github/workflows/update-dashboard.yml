name: Update Grading Dashboard

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      force_full_scan:
        description: 'Force full scan of all repos (ignore timestamps)'
        required: false
        default: false
        type: boolean

permissions:
  contents: write

jobs:
  update-dashboard:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Generate Dashboard Data
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          mkdir -p dashboard/data
          mkdir -p /tmp/repos

          # All known assignment patterns
          ALL_PATTERNS="w1-file-i-o w2-csv-parsing w3-srp-linq w4-ocp-interfaces w5-lsp-isp w6-dip-abstractions w7-midterm-prep w8-midterm w9-efcore-intro"

          # Load last run timestamp
          LAST_RUN_FILE="dashboard/data/.last_run"
          LAST_RUN_TIME=""
          if [ -f "$LAST_RUN_FILE" ]; then
            LAST_RUN_TIME=$(cat "$LAST_RUN_FILE")
            echo "Last run: $LAST_RUN_TIME"
          fi

          FORCE_SCAN="${{ github.event.inputs.force_full_scan }}"
          if [ "$FORCE_SCAN" = "true" ]; then
            LAST_RUN_TIME=""
            echo "Forcing full scan"
          fi

          # Temp file for all students (will dedupe later)
          ALL_STUDENTS_FILE=$(mktemp)
          echo "[]" > "$ALL_STUDENTS_FILE"

          # Track which patterns have repos
          ACTIVE_PATTERNS=""

          # Function to analyze a student repo
          analyze_repo() {
            local repo="$1"
            local pattern="$2"
            local student_name="$3"

            echo "  Student: $student_name (repo: $repo)" >&2

            # Get repo push date
            repo_info=$(gh api "repos/WCTC-Net-Database/$repo" 2>/dev/null || echo '{}')
            pushed_at=$(echo "$repo_info" | jq -r '.pushed_at // empty')

            # Get commit date
            commits_info=$(gh api "repos/WCTC-Net-Database/$repo/commits?per_page=1" 2>/dev/null || echo '[]')
            commit_date=$(echo "$commits_info" | jq -r '.[0].commit.author.date // empty')
            submitted_at="${commit_date:-$pushed_at}"

            # Check if changed since last run
            NEEDS_ANALYSIS=true
            if [ -n "$LAST_RUN_TIME" ] && [ -n "$pushed_at" ]; then
              last_run_epoch=$(date -d "$LAST_RUN_TIME" +%s 2>/dev/null || echo 0)
              pushed_epoch=$(date -d "$pushed_at" +%s 2>/dev/null || echo 0)
              if [ "$pushed_epoch" -le "$last_run_epoch" ]; then
                NEEDS_ANALYSIS=false
                echo "    -> Skipping deep analysis (no changes)" >&2
              fi
            fi

            # Build status
            build_status="unknown"
            build_url=""
            run_info=$(gh api "repos/WCTC-Net-Database/$repo/actions/runs?per_page=1" 2>/dev/null || echo '{"total_count":0}')
            if echo "$run_info" | jq -e '.workflow_runs[0]' > /dev/null 2>&1; then
              build_status=$(echo "$run_info" | jq -r '.workflow_runs[0].conclusion // .workflow_runs[0].status')
              build_url=$(echo "$run_info" | jq -r '.workflow_runs[0].html_url')
            fi

            # SonarCloud metrics
            sonar_key="WCTC-Net-Database_${repo}"
            maintainability="-"
            code_smells="-"
            bugs="-"
            vulnerabilities="-"
            reliability="-"
            security="-"
            duplication="-"
            lines_of_code="-"

            if [ -n "$SONAR_TOKEN" ]; then
              sonar_response=$(curl -s -u "${SONAR_TOKEN}:" \
                "https://sonarcloud.io/api/measures/component?component=${sonar_key}&metricKeys=bugs,vulnerabilities,code_smells,sqale_rating,reliability_rating,security_rating,duplicated_lines_density,ncloc" \
                2>/dev/null || echo '{}')

              if echo "$sonar_response" | jq -e '.component.measures' > /dev/null 2>&1; then
                sqale=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="sqale_rating") | .value' 2>/dev/null || echo "")
                case "$sqale" in "1.0") maintainability="A";; "2.0") maintainability="B";; "3.0") maintainability="C";; "4.0") maintainability="D";; "5.0") maintainability="E";; esac

                rel=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="reliability_rating") | .value' 2>/dev/null || echo "")
                case "$rel" in "1.0") reliability="A";; "2.0") reliability="B";; "3.0") reliability="C";; "4.0") reliability="D";; "5.0") reliability="E";; esac

                sec=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="security_rating") | .value' 2>/dev/null || echo "")
                case "$sec" in "1.0") security="A";; "2.0") security="B";; "3.0") security="C";; "4.0") security="D";; "5.0") security="E";; esac

                code_smells=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="code_smells") | .value' 2>/dev/null || echo "-")
                bugs=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="bugs") | .value' 2>/dev/null || echo "-")
                vulnerabilities=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="vulnerabilities") | .value' 2>/dev/null || echo "-")
                duplication=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="duplicated_lines_density") | .value' 2>/dev/null || echo "-")
                lines_of_code=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="ncloc") | .value' 2>/dev/null || echo "-")
              fi
            fi

            # Initialize analysis vars
            todo_count=0
            todo_locations="[]"
            student_comments="[]"
            stretch_goals="[]"
            has_stretch="false"

            # Stretch patterns based on assignment
            STRETCH_PATTERNS=""
            case "$pattern" in
              "w1-file-i-o"|"w2-csv-parsing") STRETCH_PATTERNS="CsvHelper" ;;
            esac

            # Deep analysis if needed
            if [ "$NEEDS_ANALYSIS" = true ]; then
              echo "    -> Cloning for analysis..." >&2
              REPO_DIR="/tmp/repos/$repo"
              rm -rf "$REPO_DIR"

              if gh repo clone "WCTC-Net-Database/$repo" "$REPO_DIR" --depth 1 2>/dev/null; then
                echo "    -> Analyzing code..." >&2

                todos_file=$(mktemp)
                comments_file=$(mktemp)
                echo "[" > "$todos_file"
                echo "[" > "$comments_file"
                first_todo=true
                first_comment=true

                while IFS= read -r cs_file; do
                  [ -z "$cs_file" ] && continue
                  filename=$(basename "$cs_file")
                  line_num=0

                  while IFS= read -r line || [ -n "$line" ]; do
                    line_num=$((line_num + 1))

                    if echo "$line" | grep -qE 'TODO:|TODO |// TODO|FIXME|HACK:'; then
                      todo_count=$((todo_count + 1))
                      if [ "$first_todo" = true ]; then first_todo=false; else echo "," >> "$todos_file"; fi
                      echo "\"${filename}:${line_num}\"" >> "$todos_file"
                    fi

                    if echo "$line" | grep -qE '^\s*(//|/\*|\*)'; then
                      if echo "$line" | grep -qiE '\?\s*$|is this|should I|not sure|confused|help|question:|ask instructor|review this|\*Disclosure\*'; then
                        if [ "$first_comment" = true ]; then first_comment=false; else echo "," >> "$comments_file"; fi
                        escaped=$(echo "$line" | sed 's/\\/\\\\/g; s/"/\\"/g' | tr -d '\r\t')
                        echo "{\"file\":\"${filename}\",\"line\":${line_num},\"text\":\"${escaped}\"}" >> "$comments_file"
                      fi
                    fi
                  done < "$cs_file"

                  if [ -n "$STRETCH_PATTERNS" ] && [ "$has_stretch" = "false" ]; then
                    if grep -q "$STRETCH_PATTERNS" "$cs_file" 2>/dev/null; then
                      has_stretch="true"
                      stretch_goals="[\"CsvHelper library implementation\"]"
                    fi
                  fi
                done < <(find "$REPO_DIR" -name "*.cs" -type f ! -path "*/bin/*" ! -path "*/obj/*" 2>/dev/null)

                echo "]" >> "$todos_file"
                echo "]" >> "$comments_file"
                todo_locations=$(cat "$todos_file")
                student_comments=$(cat "$comments_file")
                rm -f "$todos_file" "$comments_file"
                rm -rf "$REPO_DIR"
              fi
            fi

            # Generate notes
            notes="[]"
            comment_count=$(echo "$student_comments" | jq 'length' 2>/dev/null || echo 0)

            if [ "$todo_count" -gt 5 ]; then
              notes="[\"Many TODOs remaining - likely incomplete\"]"
            elif [ "$todo_count" -gt 0 ]; then
              notes="[\"${todo_count} TODOs remaining\"]"
            fi

            if [ "$has_stretch" = "true" ]; then
              notes=$(echo "$notes" | jq '. + ["Completed stretch goal(s)"]')
            fi
            if [ "$comment_count" -gt 0 ]; then
              notes=$(echo "$notes" | jq --arg c "$comment_count student comment(s) to review" '. + [$c]')
            fi

            # Calculate score
            estimated_score=100
            needs_review="false"

            [ "$build_status" = "failure" ] && estimated_score=$((estimated_score - 30))
            if [ "$todo_count" -gt 5 ]; then
              estimated_score=$((estimated_score - 20))
              needs_review="true"
            elif [ "$todo_count" -gt 0 ]; then
              estimated_score=$((estimated_score - todo_count * 3))
            fi
            [ "$maintainability" = "D" ] || [ "$maintainability" = "E" ] && estimated_score=$((estimated_score - 10))
            [ "$comment_count" -gt 0 ] && needs_review="true"
            [ "$estimated_score" -lt 0 ] && estimated_score=0

            # Output student JSON
            jq -n \
              --arg name "$student_name" \
              --arg repo "$repo" \
              --arg pattern "$pattern" \
              --arg submitted "$submitted_at" \
              --arg pushed "$pushed_at" \
              --arg bstatus "$build_status" \
              --arg burl "$build_url" \
              --arg skey "$sonar_key" \
              --arg maint "$maintainability" \
              --arg smells "$code_smells" \
              --arg bugs "$bugs" \
              --arg vulns "$vulnerabilities" \
              --arg rel "$reliability" \
              --arg sec "$security" \
              --arg dup "$duplication" \
              --arg loc "$lines_of_code" \
              --argjson todocount "$todo_count" \
              --argjson commentcount "$comment_count" \
              --argjson hasstretch "$has_stretch" \
              --argjson needsreview "$needs_review" \
              --argjson score "$estimated_score" \
              --argjson comments "$student_comments" \
              --argjson todos "$todo_locations" \
              --argjson stretch "$stretch_goals" \
              --argjson notes "$notes" \
              '{
                name: $name,
                repo: $repo,
                assignmentPattern: $pattern,
                submittedAt: $submitted,
                pushedAt: $pushed,
                build: { status: $bstatus, url: $burl },
                sonar: {
                  projectKey: $skey,
                  maintainability: $maint,
                  codeSmells: $smells,
                  bugs: $bugs,
                  vulnerabilities: $vulns,
                  reliability: $rel,
                  security: $sec,
                  duplication: $dup,
                  linesOfCode: $loc
                },
                todoCount: $todocount,
                studentComments: $commentcount,
                hasStretch: $hasstretch,
                needsReview: $needsreview,
                estimatedScore: $score,
                comments: $comments,
                todos: $todos,
                stretchGoals: $stretch,
                notes: $notes
              }'
          }

          # Process all patterns
          for pattern in $ALL_PATTERNS; do
            echo ""
            echo "=========================================="
            echo "Processing pattern: $pattern"
            echo "=========================================="

            repos=$(gh repo list WCTC-Net-Database --limit 500 --json name -q '.[].name' | grep "^${pattern}-" | grep -v "^${pattern}$" || true)

            if [ -z "$repos" ]; then
              echo "No repos found for $pattern"
              continue
            fi

            ACTIVE_PATTERNS="$ACTIVE_PATTERNS $pattern"

            # Start per-pattern JSON
            pattern_file="dashboard/data/${pattern}.json"
            echo "{" > "$pattern_file"
            echo "  \"assignment\": \"$pattern\"," >> "$pattern_file"
            echo "  \"generated\": \"$(date -u '+%Y-%m-%dT%H:%M:%SZ')\"," >> "$pattern_file"
            echo "  \"students\": [" >> "$pattern_file"

            first_student=true

            for repo in $repos; do
              student_name="${repo#${pattern}-}"

              if [ "$first_student" = true ]; then
                first_student=false
              else
                echo "," >> "$pattern_file"
              fi

              # Analyze and get JSON
              student_json=$(analyze_repo "$repo" "$pattern" "$student_name")

              # Add to pattern file (without assignmentPattern field for backward compat)
              echo "$student_json" | jq 'del(.assignmentPattern, .pushedAt)' >> "$pattern_file"

              # Add to all students collection
              tmp_all=$(mktemp)
              jq --argjson student "$student_json" '. += [$student]' "$ALL_STUDENTS_FILE" > "$tmp_all"
              mv "$tmp_all" "$ALL_STUDENTS_FILE"
            done

            echo "  ]" >> "$pattern_file"
            echo "}" >> "$pattern_file"

            # Fix JSON formatting
            tmp=$(mktemp)
            jq '.' "$pattern_file" > "$tmp" && mv "$tmp" "$pattern_file"

            echo "Completed $pattern"
          done

          # Generate assignments.json from active patterns
          echo "Generating assignments.json..."
          echo '{"assignments":[' > dashboard/data/assignments.json
          first=true
          for pattern in $ACTIVE_PATTERNS; do
            if [ "$first" = true ]; then first=false; else echo ',' >> dashboard/data/assignments.json; fi
            name=$(echo "$pattern" | sed 's/-/ /g' | sed 's/\b\(.\)/\u\1/g')
            echo "{\"pattern\":\"$pattern\",\"name\":\"$name\"}" >> dashboard/data/assignments.json
          done
          echo ']}' >> dashboard/data/assignments.json

          # Generate current.json - deduplicated by student (keep most recently pushed)
          echo ""
          echo "=========================================="
          echo "Generating current.json (deduplicated)"
          echo "=========================================="

          jq -s '.[0] | group_by(.name) | map(sort_by(.pushedAt) | reverse | .[0]) | sort_by(.name)' "$ALL_STUDENTS_FILE" > /tmp/deduped.json

          jq -n --argjson students "$(cat /tmp/deduped.json)" \
            --arg generated "$(date -u '+%Y-%m-%dT%H:%M:%SZ')" \
            '{
              generated: $generated,
              students: $students
            }' > dashboard/data/current.json

          echo "Generated current.json with $(jq '.students | length' dashboard/data/current.json) unique students"

          # Update history with date-indexed snapshot
          echo ""
          echo "Updating history..."
          HISTORY_FILE="dashboard/data/history.json"
          if [ ! -f "$HISTORY_FILE" ]; then
            echo '{"snapshots":[]}' > "$HISTORY_FILE"
          fi

          # Create snapshot with all students (summary data only)
          snapshot_date=$(date -u '+%Y-%m-%dT%H:%M:%SZ')
          snapshot_students=$(jq '[.[] | {name, repo, assignmentPattern, buildStatus: .build.status, estimatedScore, todoCount, hasStretch, maintainability: .sonar.maintainability, submittedAt}]' /tmp/deduped.json)

          tmp_history=$(mktemp)
          jq --arg date "$snapshot_date" --argjson students "$snapshot_students" \
            '.snapshots += [{date: $date, students: $students}] | .snapshots = .snapshots[-100:]' \
            "$HISTORY_FILE" > "$tmp_history" && mv "$tmp_history" "$HISTORY_FILE"

          # Cleanup
          rm -f "$ALL_STUDENTS_FILE" /tmp/deduped.json

          # Save last run timestamp
          date -u '+%Y-%m-%dT%H:%M:%SZ' > "$LAST_RUN_FILE"

          echo ""
          echo "Dashboard update complete!"

      - name: Commit and Push
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add dashboard/data/
          git diff --staged --quiet || git commit -m "Update dashboard data $(date -u '+%Y-%m-%d %H:%M UTC')"
          git push
