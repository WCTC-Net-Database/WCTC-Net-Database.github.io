name: Update Grading Dashboard

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      force_full_scan:
        description: 'Force full scan of all repos (ignore timestamps)'
        required: false
        default: false
        type: boolean

permissions:
  contents: write

jobs:
  update-dashboard:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Generate Dashboard Data
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          mkdir -p dashboard/data
          mkdir -p /tmp/repos

          # All known assignment patterns
          ALL_PATTERNS="w1-file-i-o w2-csv-parsing w3-srp-linq w4-ocp-interfaces w5-lsp-isp w6-dip-abstractions w7-midterm-prep w8-midterm w9-efcore-intro"

          # Load last run timestamp
          LAST_RUN_FILE="dashboard/data/.last_run"
          LAST_RUN_TIME=""
          if [ -f "$LAST_RUN_FILE" ]; then
            LAST_RUN_TIME=$(cat "$LAST_RUN_FILE")
            echo "Last run: $LAST_RUN_TIME"
          fi

          FORCE_SCAN="${{ github.event.inputs.force_full_scan }}"
          if [ "$FORCE_SCAN" = "true" ]; then
            LAST_RUN_TIME=""
            echo "Forcing full scan"
          fi

          # Temp file for all students (will dedupe later)
          ALL_STUDENTS_FILE=$(mktemp)
          echo "[]" > "$ALL_STUDENTS_FILE"

          # Track which patterns have repos
          ACTIVE_PATTERNS=""

          # Function to analyze a student repo
          analyze_repo() {
            local repo="$1"
            local pattern="$2"
            local student_name="$3"

            echo "  Student: $student_name (repo: $repo)" >&2

            # Get repo push date
            repo_info=$(gh api "repos/WCTC-Net-Database/$repo" 2>/dev/null || echo '{}')
            pushed_at=$(echo "$repo_info" | jq -r '.pushed_at // empty')

            # Get commit date
            commits_info=$(gh api "repos/WCTC-Net-Database/$repo/commits?per_page=1" 2>/dev/null || echo '[]')
            commit_date=$(echo "$commits_info" | jq -r '.[0].commit.author.date // empty')
            submitted_at="${commit_date:-$pushed_at}"

            # Count student commits (exclude instructor/bot/workflow commits)
            all_commits=$(gh api "repos/WCTC-Net-Database/$repo/commits?per_page=100" 2>/dev/null || echo '[]')
            student_commit_count=$(echo "$all_commits" | jq '[.[] | select(
              (.author.login // "" | test("^(mcarthey|github-classroom\\[bot\\]|web-flow)$") | not) and
              (.commit.author.name // "" | test("^(WCTC Instructor|github-classroom\\[bot\\])$") | not) and
              (.commit.message // "" | test("(?i)(workflow|sonarcloud)") | not)
            )] | length' 2>/dev/null || echo "0")
            student_commit_count=${student_commit_count:-0}
            echo "    -> Student commits: $student_commit_count" >&2

            # Check if changed since last run
            NEEDS_ANALYSIS=true
            if [ -n "$LAST_RUN_TIME" ] && [ -n "$pushed_at" ]; then
              last_run_epoch=$(date -d "$LAST_RUN_TIME" +%s 2>/dev/null || echo 0)
              pushed_epoch=$(date -d "$pushed_at" +%s 2>/dev/null || echo 0)
              if [ "$pushed_epoch" -le "$last_run_epoch" ]; then
                NEEDS_ANALYSIS=false
                echo "    -> Skipping deep analysis (no changes)" >&2
              fi
            fi

            # Build status
            build_status="unknown"
            build_url=""
            build_error_step=""
            build_error_lines="[]"
            run_info=$(gh api "repos/WCTC-Net-Database/$repo/actions/runs?per_page=1" 2>/dev/null || echo '{"total_count":0}')
            if echo "$run_info" | jq -e '.workflow_runs[0]' > /dev/null 2>&1; then
              build_status=$(echo "$run_info" | jq -r '.workflow_runs[0].conclusion // .workflow_runs[0].status')
              build_url=$(echo "$run_info" | jq -r '.workflow_runs[0].html_url')

              # Extract error details for failed builds
              if [ "$build_status" = "failure" ]; then
                run_id=$(echo "$run_info" | jq -r '.workflow_runs[0].id')
                echo "    -> Build failed, extracting error details..." >&2

                # Get failed step name from jobs API
                jobs_info=$(gh api "repos/WCTC-Net-Database/$repo/actions/runs/$run_id/jobs?per_page=5" 2>/dev/null || echo '{}')
                build_error_step=$(echo "$jobs_info" | jq -r '[.jobs[].steps[] | select(.conclusion == "failure")] | .[0].name // empty' 2>/dev/null || echo "")

                # Get failed log and extract error lines
                error_log=$(gh run view "$run_id" --repo "WCTC-Net-Database/$repo" --log-failed 2>/dev/null || echo "")
                if [ -n "$error_log" ]; then
                  build_error_lines=$(echo "$error_log" \
                    | grep -iE 'error [A-Z]{2}[0-9]|: error|Build FAILED|FAILED|Exception:' \
                    | sed 's/^.*\t.*\t[0-9T:.Z-]* //' \
                    | head -10 \
                    | jq -R -s 'split("\n") | map(select(length > 0))' 2>/dev/null || echo '[]')
                fi
              fi
            fi

            # SonarCloud metrics
            sonar_key="WCTC-Net-Database_${repo}"
            maintainability="-"
            code_smells="-"
            bugs="-"
            vulnerabilities="-"
            reliability="-"
            security="-"
            duplication="-"
            lines_of_code="-"

            if [ -n "$SONAR_TOKEN" ]; then
              sonar_response=$(curl -s -u "${SONAR_TOKEN}:" \
                "https://sonarcloud.io/api/measures/component?component=${sonar_key}&metricKeys=bugs,vulnerabilities,code_smells,sqale_rating,reliability_rating,security_rating,duplicated_lines_density,ncloc" \
                2>/dev/null || echo '{}')

              if echo "$sonar_response" | jq -e '.component.measures' > /dev/null 2>&1; then
                sqale=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="sqale_rating") | .value' 2>/dev/null || echo "")
                case "$sqale" in "1.0") maintainability="A";; "2.0") maintainability="B";; "3.0") maintainability="C";; "4.0") maintainability="D";; "5.0") maintainability="E";; esac

                rel=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="reliability_rating") | .value' 2>/dev/null || echo "")
                case "$rel" in "1.0") reliability="A";; "2.0") reliability="B";; "3.0") reliability="C";; "4.0") reliability="D";; "5.0") reliability="E";; esac

                sec=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="security_rating") | .value' 2>/dev/null || echo "")
                case "$sec" in "1.0") security="A";; "2.0") security="B";; "3.0") security="C";; "4.0") security="D";; "5.0") security="E";; esac

                code_smells=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="code_smells") | .value' 2>/dev/null || echo "-")
                bugs=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="bugs") | .value' 2>/dev/null || echo "-")
                vulnerabilities=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="vulnerabilities") | .value' 2>/dev/null || echo "-")
                duplication=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="duplicated_lines_density") | .value' 2>/dev/null || echo "-")
                lines_of_code=$(echo "$sonar_response" | jq -r '.component.measures[] | select(.metric=="ncloc") | .value' 2>/dev/null || echo "-")
              fi
            fi

            # Initialize analysis vars
            todo_count=0
            todo_locations="[]"
            student_comments="[]"
            stretch_goals="[]"
            has_stretch="false"

            # Deep analysis if needed
            if [ "$NEEDS_ANALYSIS" = true ]; then
              echo "    -> Cloning for analysis..." >&2
              REPO_DIR="/tmp/repos/$repo"
              rm -rf "$REPO_DIR"

              clone_output=$(gh repo clone "WCTC-Net-Database/$repo" "$REPO_DIR" -- --depth 1 2>&1) && clone_success=true || clone_success=false
              if [ "$clone_success" = "true" ]; then
                echo "    -> Analyzing code..." >&2

                todos_file=$(mktemp)
                comments_file=$(mktemp)
                echo "[" > "$todos_file"
                echo "[" > "$comments_file"
                first_todo=true
                first_comment=true

                while IFS= read -r cs_file; do
                  [ -z "$cs_file" ] && continue
                  filename=$(basename "$cs_file")
                  line_num=0

                  while IFS= read -r line || [ -n "$line" ]; do
                    line_num=$((line_num + 1))

                    if echo "$line" | grep -qE 'TODO:|TODO |// TODO|FIXME|HACK:'; then
                      todo_count=$((todo_count + 1))
                      if [ "$first_todo" = true ]; then first_todo=false; else echo "," >> "$todos_file"; fi
                      echo "\"${filename}:${line_num}\"" >> "$todos_file"
                    fi

                    if echo "$line" | grep -qE '^\s*(//|/\*|\*)'; then
                      if echo "$line" | grep -qiE '\?\s*$|is this|should I|not sure|confused|help|question:|ask instructor|review this|\*Disclosure\*'; then
                        if [ "$first_comment" = true ]; then first_comment=false; else echo "," >> "$comments_file"; fi
                        escaped=$(echo "$line" | sed 's/\\/\\\\/g; s/"/\\"/g' | tr -d '\r\t')
                        echo "{\"file\":\"${filename}\",\"line\":${line_num},\"text\":\"${escaped}\"}" >> "$comments_file"
                      fi
                    fi
                  done < "$cs_file"

                done < <(find "$REPO_DIR" -name "*.cs" -type f ! -path "*/bin/*" ! -path "*/obj/*" 2>/dev/null)

                echo "]" >> "$todos_file"
                echo "]" >> "$comments_file"
                todo_locations=$(cat "$todos_file")
                student_comments=$(cat "$comments_file")
                rm -f "$todos_file" "$comments_file"

                # Detect ALL known stretch goals (check every repo for all patterns)
                echo "    -> Checking stretch goals..." >&2
                stretch_list=""

                # NuGet packages (.csproj)
                if grep -rq "CsvHelper" "$REPO_DIR" --include="*.csproj" 2>/dev/null; then
                  stretch_list="${stretch_list}CsvHelper "
                fi
                if grep -rq "Spectre\.Console" "$REPO_DIR" --include="*.csproj" 2>/dev/null; then
                  stretch_list="${stretch_list}Spectre.Console "
                fi

                # Code patterns (.cs files, skip bin/obj)
                CS_DIR="$REPO_DIR"
                CS_INC="--include=*.cs"
                CS_EXC="--exclude-dir=bin --exclude-dir=obj"

                if grep -rq $CS_INC $CS_EXC "JsonFileHandler\|IJsonFileHandler" "$CS_DIR" 2>/dev/null; then
                  stretch_list="${stretch_list}JsonFileHandler "
                fi
                if grep -rq $CS_INC $CS_EXC "ICommand" "$CS_DIR" 2>/dev/null && \
                   grep -rq $CS_INC $CS_EXC "\.Execute()" "$CS_DIR" 2>/dev/null; then
                  stretch_list="${stretch_list}CommandPattern "
                fi
                char_class_count=$(grep -rl $CS_INC $CS_EXC ": CharacterBase" "$CS_DIR" 2>/dev/null | wc -l)
                if [ "$char_class_count" -ge 3 ]; then
                  stretch_list="${stretch_list}ExtraCharacters "
                fi
                if grep -rq $CS_INC $CS_EXC "GetTotalAttack\|GetTotalDefense" "$CS_DIR" 2>/dev/null; then
                  stretch_list="${stretch_list}ItemCombat "
                fi
                if grep -rq $CS_INC $CS_EXC "SaveChanges" "$CS_DIR" 2>/dev/null && \
                   grep -rq $CS_INC $CS_EXC "DbContext" "$CS_DIR" 2>/dev/null; then
                  stretch_list="${stretch_list}EFCoreUpdate "
                fi

                # Convert to JSON array
                if [ -n "$stretch_list" ]; then
                  has_stretch="true"
                  stretch_goals=$(echo "$stretch_list" | tr ' ' '\n' | grep -v '^$' | jq -R -s 'split("\n") | map(select(length > 0))')
                  echo "    -> Found: $stretch_list" >&2
                fi

                rm -rf "$REPO_DIR"
              else
                echo "    -> Clone failed: $clone_output" >&2
              fi
            fi

            # Generate notes
            notes="[]"
            comment_count=$(echo "$student_comments" | jq 'length' 2>/dev/null || echo 0)

            if [ "$todo_count" -gt 5 ]; then
              notes="[\"Many TODOs remaining - likely incomplete\"]"
            elif [ "$todo_count" -gt 0 ]; then
              notes="[\"${todo_count} TODOs remaining\"]"
            fi

            if [ "$has_stretch" = "true" ]; then
              notes=$(echo "$notes" | jq '. + ["Completed stretch goal(s)"]')
            fi
            if [ "$comment_count" -gt 0 ]; then
              notes=$(echo "$notes" | jq --arg c "$comment_count student comment(s) to review" '. + [$c]')
            fi

            # Calculate score
            estimated_score=100
            needs_review="false"

            [ "$build_status" = "failure" ] && estimated_score=$((estimated_score - 30))
            if [ "$todo_count" -gt 5 ]; then
              estimated_score=$((estimated_score - 20))
              needs_review="true"
            elif [ "$todo_count" -gt 0 ]; then
              estimated_score=$((estimated_score - todo_count * 3))
            fi
            [ "$maintainability" = "D" ] || [ "$maintainability" = "E" ] && estimated_score=$((estimated_score - 10))
            [ "$comment_count" -gt 0 ] && needs_review="true"
            [ "$estimated_score" -lt 0 ] && estimated_score=0

            # Template-only detection: override score when no student work
            is_template_only="false"
            if [ "$student_commit_count" -eq 0 ]; then
              is_template_only="true"
              estimated_score=0
              needs_review="true"
              notes=$(echo "$notes" | jq '. + ["Template only - no student commits detected"]')
              echo "    -> Template only (no student commits)" >&2
            fi

            # Output student JSON
            jq -n \
              --arg name "$student_name" \
              --arg repo "$repo" \
              --arg pattern "$pattern" \
              --arg submitted "$submitted_at" \
              --arg pushed "$pushed_at" \
              --arg bstatus "$build_status" \
              --arg burl "$build_url" \
              --arg berrstep "$build_error_step" \
              --argjson berrlines "$build_error_lines" \
              --arg skey "$sonar_key" \
              --arg maint "$maintainability" \
              --arg smells "$code_smells" \
              --arg bugs "$bugs" \
              --arg vulns "$vulnerabilities" \
              --arg rel "$reliability" \
              --arg sec "$security" \
              --arg dup "$duplication" \
              --arg loc "$lines_of_code" \
              --argjson todocount "$todo_count" \
              --argjson commentcount "$comment_count" \
              --argjson hasstretch "$has_stretch" \
              --argjson needsreview "$needs_review" \
              --argjson score "$estimated_score" \
              --argjson comments "$student_comments" \
              --argjson todos "$todo_locations" \
              --argjson stretch "$stretch_goals" \
              --argjson scommits "$student_commit_count" \
              --argjson istemplate "$is_template_only" \
              --argjson notes "$notes" \
              '{
                name: $name,
                repo: $repo,
                assignmentPattern: $pattern,
                submittedAt: $submitted,
                pushedAt: $pushed,
                build: { status: $bstatus, url: $burl, errorStep: $berrstep, errorLines: $berrlines },
                sonar: {
                  projectKey: $skey,
                  maintainability: $maint,
                  codeSmells: $smells,
                  bugs: $bugs,
                  vulnerabilities: $vulns,
                  reliability: $rel,
                  security: $sec,
                  duplication: $dup,
                  linesOfCode: $loc
                },
                todoCount: $todocount,
                studentComments: $commentcount,
                hasStretch: $hasstretch,
                needsReview: $needsreview,
                estimatedScore: $score,
                comments: $comments,
                todos: $todos,
                stretchGoals: $stretch,
                studentCommitCount: $scommits,
                isTemplateOnly: $istemplate,
                notes: $notes
              }'
          }

          # Process all patterns
          for pattern in $ALL_PATTERNS; do
            echo ""
            echo "=========================================="
            echo "Processing pattern: $pattern"
            echo "=========================================="

            repos=$(gh repo list WCTC-Net-Database --limit 500 --json name -q '.[].name' | grep "^${pattern}-" | grep -v "^${pattern}$" || true)

            if [ -z "$repos" ]; then
              echo "No repos found for $pattern"
              continue
            fi

            ACTIVE_PATTERNS="$ACTIVE_PATTERNS $pattern"

            # Start per-pattern JSON
            pattern_file="dashboard/data/${pattern}.json"
            echo "{" > "$pattern_file"
            echo "  \"assignment\": \"$pattern\"," >> "$pattern_file"
            echo "  \"generated\": \"$(date -u '+%Y-%m-%dT%H:%M:%SZ')\"," >> "$pattern_file"
            echo "  \"students\": [" >> "$pattern_file"

            first_student=true

            for repo in $repos; do
              student_name="${repo#${pattern}-}"

              if [ "$first_student" = true ]; then
                first_student=false
              else
                echo "," >> "$pattern_file"
              fi

              # Analyze and get JSON
              student_json=$(analyze_repo "$repo" "$pattern" "$student_name")

              # Add to pattern file (without assignmentPattern field for backward compat)
              echo "$student_json" | jq 'del(.assignmentPattern, .pushedAt)' >> "$pattern_file"

              # Add to all students collection
              tmp_all=$(mktemp)
              jq --argjson student "$student_json" '. += [$student]' "$ALL_STUDENTS_FILE" > "$tmp_all"
              mv "$tmp_all" "$ALL_STUDENTS_FILE"
            done

            echo "  ]" >> "$pattern_file"
            echo "}" >> "$pattern_file"

            # Fix JSON formatting
            tmp=$(mktemp)
            jq '.' "$pattern_file" > "$tmp" && mv "$tmp" "$pattern_file"

            echo "Completed $pattern"
          done

          # Generate assignments.json from active patterns
          echo "Generating assignments.json..."
          echo '{"assignments":[' > dashboard/data/assignments.json
          first=true
          for pattern in $ACTIVE_PATTERNS; do
            if [ "$first" = true ]; then first=false; else echo ',' >> dashboard/data/assignments.json; fi
            name=$(echo "$pattern" | sed 's/-/ /g' | sed 's/\b\(.\)/\u\1/g')
            echo "{\"pattern\":\"$pattern\",\"name\":\"$name\"}" >> dashboard/data/assignments.json
          done
          echo ']}' >> dashboard/data/assignments.json

          # Generate current.json - all student+assignment entries (no dedup)
          echo ""
          echo "=========================================="
          echo "Generating current.json (all entries)"
          echo "=========================================="

          jq -s '.[0] | sort_by(.name)' "$ALL_STUDENTS_FILE" > /tmp/all_students.json

          jq -n --argjson students "$(cat /tmp/all_students.json)" \
            --arg generated "$(date -u '+%Y-%m-%dT%H:%M:%SZ')" \
            '{
              generated: $generated,
              students: $students
            }' > dashboard/data/current.json

          echo "Generated current.json with $(jq '.students | length' dashboard/data/current.json) student entries"

          # Update history with date-indexed snapshot
          echo ""
          echo "Updating history..."
          HISTORY_FILE="dashboard/data/history.json"
          if [ ! -f "$HISTORY_FILE" ]; then
            echo '{"snapshots":[]}' > "$HISTORY_FILE"
          fi

          # Create snapshot with all students (summary data only)
          snapshot_date=$(date -u '+%Y-%m-%dT%H:%M:%SZ')
          snapshot_students=$(jq '[.[] | {name, repo, assignmentPattern, buildStatus: .build.status, estimatedScore, todoCount, hasStretch, maintainability: .sonar.maintainability, submittedAt, studentCommitCount, isTemplateOnly}]' /tmp/all_students.json)

          tmp_history=$(mktemp)
          jq --arg date "$snapshot_date" --argjson students "$snapshot_students" \
            '.snapshots += [{date: $date, students: $students}] | .snapshots = .snapshots[-100:]' \
            "$HISTORY_FILE" > "$tmp_history" && mv "$tmp_history" "$HISTORY_FILE"

          # Cleanup
          rm -f "$ALL_STUDENTS_FILE" /tmp/all_students.json

          # Save last run timestamp
          date -u '+%Y-%m-%dT%H:%M:%SZ' > "$LAST_RUN_FILE"

          echo ""
          echo "Dashboard update complete!"

      - name: Commit and Push
        id: commit
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add dashboard/data/
          if git diff --staged --quiet; then
            echo "No changes to commit"
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            git commit -m "Update dashboard data $(date -u '+%Y-%m-%d %H:%M UTC')"
            git push
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Trigger Pages Deployment
        if: steps.commit.outputs.changed == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          echo "Triggering GitHub Pages deployment..."
          gh workflow run static.yml
